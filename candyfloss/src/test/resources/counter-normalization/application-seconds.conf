
kafka {
  application.id = "kafka-streams-101"
  bootstrap.servers = "localhost:29092"
  acks = all
  enable.idempotence = true
  key.serializer = "org.apache.kafka.common.serialization.StringSerializer"
  value.serializer = "org.apache.kafka.common.serialization.StringSerializer"
  metrics.recording.level = DEBUG
}

kstream {
  input.topic.name = daisy.prod.device-json-raw
  discard.topic.name = daisy.dev.device-json-flat
  dlq.topic.name = daisy.dev.device-json-flat-dlq
  state.store.name = daisy.dev.device-counters-store
  state.store.max.counter.cache.age = 10000
  state.store.int.counter.wrap.limit = 10000
  state.store.long.counter.wrap.limit = 1000000
  state.store.long.counter.time.ms = 300000 # allow max 5 min for counter wrap around otherwise it's a reset
  state.store.delete.scan.frequency.days = 7 # how often to trigger scanning for old unused counters and delete them
  pipeline = {
    testStep {
      output.topic.name = outputTest
      file = "counter-normalization/config-seconds.json"
    }
  }
}
